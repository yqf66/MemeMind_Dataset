# MemeMind
This is a project that introduces a harmful meme dataset, which for the first time adds CoT annotation to enable the model to mimic human thinking to infer whether memes are harmful.

## Paper
This work is introduced in our paper: MemeMind: ***A Large-Scale Multimodal Dataset with Chain-of-Thought Reasoning for Harmful Meme Detection***.

## Dataset
You can view and download our dataset MemeMind through this link: https://huggingface.co/datasets/yubb66/MemeMind. This includes all harmful meme samples and annotation files in the dataset, divided into training and testing sets.

## Supplementary Material
The supplementary materials for our paper have been provided in detail in the Supplementary folder, including **reference**, **appendices**, **annotated visualization examples of the dataset**, and **visualization examples of the output results of our method model**.

## Codes
The relevant code for our method will be **open sourced soon** after we have organized it.

